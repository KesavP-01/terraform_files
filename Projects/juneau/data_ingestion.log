2025-06-25 09:07:33 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 09:07:33 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 09:07:33 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 09:07:33 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 09:07:33 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 09:07:33 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 09:07:33 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 09:07:33 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 09:07:33 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 09:07:33 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 09:07:33 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 09:07:33 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 09:07:33 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 09:07:33 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 09:07:33 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 09:07:33 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 09:07:33 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 09:07:33 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 09:07:33 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 11:06:19 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 11:06:19 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 11:06:19 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 11:06:19 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 11:06:19 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 11:06:19 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 11:06:19 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 11:06:19 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 11:06:19 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 11:06:19 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 11:06:19 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 11:06:19 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 11:06:20 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 11:06:20 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 11:06:20 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 11:06:20 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 11:06:20 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 11:06:20 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 11:06:20 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 11:06:20 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 11:06:20 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 11:06:20 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 11:06:20 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 11:06:20 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 11:06:20 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 11:41:44 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 11:41:44 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 11:41:44 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 11:41:44 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 11:41:45 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 11:41:45 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 11:41:45 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 11:41:45 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 11:41:45 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 11:41:45 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 11:41:45 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 11:41:45 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 11:41:45 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 11:41:45 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 11:41:45 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 11:41:45 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 11:41:45 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 11:41:45 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 11:41:45 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 11:41:45 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 11:41:45 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 14:00:30 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 14:00:30 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 14:00:30 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 14:00:30 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 14:00:31 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 14:00:31 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 14:00:31 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 14:00:31 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 14:00:31 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 14:00:31 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 14:00:31 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 14:00:31 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 14:00:31 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 14:00:31 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 14:00:31 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 14:00:31 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 14:00:31 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 14:00:31 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 14:00:31 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 14:00:31 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 14:00:31 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 15:15:48 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 15:15:48 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:15:48 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 15:15:48 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:15:48 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 15:15:48 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:15:48 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 15:15:48 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 15:15:48 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 15:15:48 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 15:15:48 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 15:15:48 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 15:15:48 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 15:15:48 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 15:15:48 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 15:15:48 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 15:15:48 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 15:15:48 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 15:15:48 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 15:16:23 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 15:16:23 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 15:16:23 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:16:23 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:16:24 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 15:16:24 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:16:24 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 15:16:24 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:16:24 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 15:16:24 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 15:16:24 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 15:16:24 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 15:16:24 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 15:16:24 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 15:16:24 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 15:16:24 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 15:16:24 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 15:16:24 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 15:16:24 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 15:16:24 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 15:16:24 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 15:28:56 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 15:28:56 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:28:56 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 15:28:56 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:28:56 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 15:28:56 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 15:28:56 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 15:28:56 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 15:28:56 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 15:28:56 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 15:28:56 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 15:28:56 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 15:28:56 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 15:28:56 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 15:28:56 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 15:28:56 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 15:28:56 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 15:28:56 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 15:28:56 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 19:08:20 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 19:08:20 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 19:08:20 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:08:20 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:08:20 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 19:08:20 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 19:08:20 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:08:20 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:08:21 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:08:21 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:08:21 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:08:21 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:08:21 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 19:08:21 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:08:21 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:08:21 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:08:21 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:08:21 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:08:21 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:08:21 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 19:08:21 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 19:08:21 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 19:08:21 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 19:32:23 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 19:32:23 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 19:32:23 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:32:23 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:32:24 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 19:32:24 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:32:24 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:32:24 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:32:24 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:32:24 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:32:24 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 19:32:24 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:32:24 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:32:24 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:32:24 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:32:24 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:32:24 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:32:24 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 19:32:24 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 19:32:24 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 19:32:24 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 19:40:02 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 19:40:02 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 19:40:02 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:40:02 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:40:02 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 19:40:02 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 19:40:02 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:40:02 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:40:03 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:40:03 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:40:03 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:40:03 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:40:03 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 19:40:03 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:40:03 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:40:03 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:40:03 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:40:03 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:40:03 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:40:03 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 19:40:03 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 19:40:03 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 19:40:03 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 19:41:50 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 19:41:50 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:41:50 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 19:41:50 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:41:50 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:41:50 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-25 19:41:50 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:41:50 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-25 19:41:50 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 19:41:50 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:41:50 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-25 19:41:50 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:41:50 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:41:50 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:41:50 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-25 19:41:50 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 19:41:50 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-25 19:41:50 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-25 19:41:50 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-30 16:02:32 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-30 16:02:32 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-30 16:02:32 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-30 16:02:32 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-30 16:02:32 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-30 16:02:32 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-30 16:02:32 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-30 16:02:32 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-30 16:02:33 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-30 16:02:33 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-30 16:02:33 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-30 16:02:33 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-30 16:02:33 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-30 16:02:33 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-30 16:02:33 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-30 16:02:33 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-30 16:02:33 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-30 16:02:33 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-30 16:02:33 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-30 16:02:33 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-30 16:02:33 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-30 16:02:33 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-30 16:02:33 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-30 16:04:13 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-30 16:04:13 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-30 16:04:13 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-30 16:04:13 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-30 16:04:13 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-30 16:04:13 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-06-30 16:04:13 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-30 16:04:13 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-06-30 16:04:13 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-30 16:04:13 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: []
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-30 16:04:13 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-06-30 16:04:13 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-30 16:04:13 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-30 16:04:13 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-30 16:04:13 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-06-30 16:04:13 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-30 16:04:13 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-06-30 16:04:13 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-06-30 16:04:13 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-07-01 13:33:44 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-07-01 13:33:44 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-07-01 13:33:44 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-07-01 13:33:44 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-07-01 13:33:45 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-07-01 13:33:45 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-07-01 13:33:45 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-07-01 13:33:45 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-07-01 13:33:45 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-07-01 13:33:45 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-07-01 13:33:45 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-07-01 13:33:45 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\dataops-admin\databricks-commercialanalytics\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: []
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: []
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-07-01 13:33:45 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-07-01 13:33:45 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-07-01 13:33:45 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-07-01 13:33:45 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-07-01 13:33:45 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-07-01 13:33:45 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-07-01 13:33:45 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-07-01 13:33:45 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-07-01 13:33:45 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-07-03 11:48:21 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-07-03 11:48:21 - data_ingestion_logger - INFO - Reading file 'test_file.csv', worksheet='None', skiprows=5
2025-07-03 11:48:21 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-07-03 11:48:21 - data_ingestion_logger - DEBUG - DataFrame read from CSV. Columns: Index(['col1', 'col2'], dtype='object')
2025-07-03 11:48:22 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-07-03 11:48:22 - data_ingestion_logger - INFO - Reading file 'test_file.xlsx', worksheet='Sheet1', skiprows=5
2025-07-03 11:48:22 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-07-03 11:48:22 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-07-03 11:48:22 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-07-03 11:48:22 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-07-03 11:48:22 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-07-03 11:48:22 - data_ingestion_logger - DEBUG - DataFrame read from Excel. Columns: Index(['col1', 'col2'], dtype='object')
2025-07-03 11:48:22 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-07-03 11:48:22 - data_ingestion_logger - INFO - Reading file 'test_file.xls', worksheet='None', skiprows=0
2025-07-03 11:48:22 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\databricks-cargo\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-07-03 11:48:22 - data_ingestion_logger - ERROR - Error reading file 'test_file.xls' with sheet 'None': Generic pandas failure
Traceback (most recent call last):
  File "C:\Users\v-sponduru\Desktop\Working Dir\databricks-cargo\databricks_asset_bundle\projects\juneau\src\functions.py", line 131, in read_excel_or_csv
    df = pd.read_excel(filename, sheet_name=worksheet, skiprows=skiprows, dtype=str)
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\v-sponduru\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Generic pandas failure
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: ['FirstName', 'LastName', 'EmailAddress']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: ['first_name', 'last_name', 'email_address']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: ['My-Column', 'Test (Special)']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: ['my_column', 'test_special']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: ['ABTest', 'CDrive']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: ['ab_test', 'c_drive']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: ['AnotherLongerWordExample']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: ['another_longer_word_example']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: ['already_correct', 'Has Space']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: ['already_correct', 'has_space']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: []
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: []
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: []
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixing column names to meet Databricks standards.
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Original columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-07-03 11:48:23 - data_ingestion_logger - DEBUG - Fixed columns: ['_leading_underscore', 'trailing_underscore_', 'column123', '123column']
2025-07-03 11:48:23 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-07-03 11:48:23 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-07-03 11:48:23 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-07-03 11:48:23 - data_ingestion_logger - ERROR - Config entry must contain 'filename' and a non-empty 'worksheets' list.
2025-07-03 11:48:23 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-07-03 11:48:23 - data_ingestion_logger - ERROR - Each worksheet info dict must include a 'table_name'.
2025-07-03 11:48:23 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
2025-07-03 11:48:23 - data_ingestion_logger - ERROR - No 'files' key found in provided config JSON.
