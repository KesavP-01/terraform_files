{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02f0fc42-e540-4169-a572-a978bbd6b0b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Temporarily functions for making this code to run\n",
    "\n",
    "def edw_pull(sql:str, numPartitions:int = 8, fetchsize:int = 10000):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Pulls data from Oracle to Databricks.\n",
    "\n",
    "    Args:\n",
    "        sql: The SQL query to execute.\n",
    "        fetchsize: The JDBC fetch size.\n",
    "        NOT USED: num_partitions: The number of partitions for the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A Spark DataFrame.\n",
    "    \"\"\"\n",
    "    import logging\n",
    "\n",
    "    try:\n",
    "        # Retrieve secrets.  Embeds credentials so they are consistent in workflows.  If credentials change, they only need to be updated here and not in each individual workflow.\n",
    "        un = dbutils.secrets.get(scope=\"CommercialAnalytics\", key=\"edw-commarsa\")\n",
    "        pw = dbutils.secrets.get(scope=\"CommercialAnalytics\", key=\"edw-commarsa-pw\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to retrieve secrets: {e}\")\n",
    "        raise\n",
    "\n",
    "    df = (\n",
    "        spark.read.format(\"jdbc\")\n",
    "        .option(\"url\", \"jdbc:oracle:thin:@reporting.datawarehouse.db.insideaag.com:1522/edwprod\")\n",
    "        .option(\"user\", un)\n",
    "        .option(\"password\", pw)\n",
    "        .option(\"query\", sql)\n",
    "        .option(\"driver\", \"oracle.jdbc.driver.OracleDriver\")\n",
    "        .option(\"fetchsize\", fetchsize) # default is 10\n",
    "        .option(\"numPartitions\", numPartitions) # max of 8 for oracle\n",
    "        # partitionColumn, lowerBound, upperBound\n",
    "        .load()\n",
    "    )\n",
    "    # display(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "163e9bd0-362f-4bc9-b3ca-eea7a44c04be",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "imports"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dab7f06-8f14-42b3-a0d4-c41f7a2ed243",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "import lib functions"
    }
   },
   "outputs": [],
   "source": [
    "local_lib = os.getcwd()\n",
    "# module_src_path = os.path.join(local_lib, \"../projects\", \"src\")\n",
    "\n",
    "print(f\"local_lib: {local_lib}\")\n",
    "print(\"File paths have been set.\")\n",
    "sys.path.append(local_lib)\n",
    "\n",
    "#import functions as fn\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d72ffb7-29e5-490b-be68-08e63ce9f6c3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "env"
    }
   },
   "outputs": [],
   "source": [
    "env = dbutils.secrets.get(scope=\"CommercialAnalytics\", key=\"env-databricks\")\n",
    "if env:\n",
    "  db_env = \"_\" + env\n",
    "else:\n",
    "  db_env = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34adb175-b5b0-491f-b241-05a66e576bda",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "set catalog"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"USE business_revenuemanagement{db_env}.an_revenuemanagement_ods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69fb88fd-97ed-4516-a23a-c355a9e0d752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Industry Schedule - OA ASMs\n",
    "> loading INDUSTRY_DW.SCHEDULE_FUTURE_AND_HISTORICAL_FACT from Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df5d8dbc-39a6-4420-b523-0b65bdffb7c0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "max flight date"
    }
   },
   "outputs": [],
   "source": [
    "oa_sql = \"\"\"\n",
    "select max(flight_dt)\n",
    "from INDUSTRY_DW.SCHEDULE_FUTURE_AND_HISTORICAL_FACT\n",
    "where flight_dt > TRUNC(SYSDATE)\n",
    "\"\"\"\n",
    "\n",
    "fn.edw_pull(oa_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "504d1c2f-bfa2-4afa-a1c8-1d67616009fa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "load"
    }
   },
   "outputs": [],
   "source": [
    "oa_sql = \"\"\"\n",
    " select\n",
    "    trunc(s.flight_dt, 'MONTH') as dptr_month,\n",
    "    concat(s.orig_apt_cd, s.dest_apt_cd) as OD,\n",
    "    CASE\n",
    "      WHEN s.oper_carr_cd IN ('AS', 'QX', 'VX') THEN 'AS'\n",
    "      WHEN s.oper_carr_cd = 'HA' THEN 'HA'\n",
    "      WHEN s.mktg_carr_cd IN ('AS', 'QX', 'VX') AND s.oper_carr_cd IN ('OO') THEN 'AS'\n",
    "      WHEN s.oper_carr_cd IS NULL AND s.mktg_carr_cd IN ('AS', 'QX', 'VX') THEN 'AS'\n",
    "      WHEN s.oper_carr_cd IS NULL AND s.mktg_carr_cd IN ('HA') THEN 'HA'\n",
    "      WHEN s.oper_carr_cd is null and s.mktg_carr_cd is null THEN null\n",
    "    ELSE 'OA' END as carr_group,\n",
    "    sum(s.RPT_TOTAL_ASM_CNT) as ASM,\n",
    "    sum(s.TOTAL_DISTANCE_MILE) as TOTAL_DISTANCE_MILE,\n",
    "    sum(s.TOTAL_SEAT_CNT) as TOTAL_SEAT_CNT\n",
    "  from INDUSTRY_DW.SCHEDULE_FUTURE_AND_HISTORICAL_FACT s\n",
    "  where\n",
    "    -- CICD TESTING --\n",
    "    trunc(s.flight_dt, 'MONTH') BETWEEN TO_DATE('2025-01-01', 'YYYY-MM-DD') and ADD_MONTHS(TRUNC(SYSDATE, 'month'), 2)\n",
    "    AND s.SERVICE_TP_CD = 'J' -- iata service type codes\n",
    "    AND s.IS_CODE_SHARE_IND = 0 -- removes codeshare flight stats\n",
    "    AND s.INTERMEDIATE_STOP_CNT = 0\n",
    "  group by\n",
    "    trunc(s.flight_dt, 'MONTH'),\n",
    "    concat(s.orig_apt_cd, s.dest_apt_cd),\n",
    "    CASE\n",
    "      WHEN s.oper_carr_cd IN ('AS', 'QX', 'VX') THEN 'AS'\n",
    "      WHEN s.oper_carr_cd = 'HA' THEN 'HA'\n",
    "      WHEN s.mktg_carr_cd IN ('AS', 'QX', 'VX') AND s.oper_carr_cd IN ('OO') THEN 'AS'\n",
    "      WHEN s.oper_carr_cd IS NULL AND s.mktg_carr_cd IN ('AS', 'QX', 'VX') THEN 'AS'\n",
    "      WHEN s.oper_carr_cd IS NULL AND s.mktg_carr_cd IN ('HA') THEN 'HA'\n",
    "      WHEN s.oper_carr_cd is null and s.mktg_carr_cd is null THEN null\n",
    "    ELSE 'OA' END\n",
    "\"\"\"\n",
    "\n",
    "ind_schd = fn.edw_pull(oa_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fc8f8c5-8956-46fe-b5fc-dc34a94edab5",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"filterGroups\":[],\"syncTimestamp\":1745452090409}",
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "transform"
    }
   },
   "outputs": [],
   "source": [
    "ind_schd = ind_schd.withColumn(\"dptr_month\", ind_schd[\"dptr_month\"].cast(\"date\")) \\\n",
    "                   .withColumn(\"ASM\", ind_schd[\"ASM\"].cast(\"int\")) \\\n",
    "                   .withColumn(\"TOTAL_DISTANCE_MILE\", ind_schd[\"TOTAL_DISTANCE_MILE\"].cast(\"int\")) \\\n",
    "                   .withColumn(\"TOTAL_SEAT_CNT\", ind_schd[\"TOTAL_SEAT_CNT\"].cast(\"int\"))\n",
    "\n",
    "ind_schd = ind_schd.select([col(c).alias(c.lower()) for c in ind_schd.columns])\n",
    "\n",
    "display(ind_schd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "637ff697-cd6c-4b98-a3d2-08e4fbe912a1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "write"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ind_schd.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"cicd_schd_fut_hist_mth_test\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "industry_schedule",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
